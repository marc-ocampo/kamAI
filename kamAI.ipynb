{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kamAI\n",
    "\n",
    "We will demonstrate a system that recognizes numbers from hand gestures.  \n",
    "It is similar to the final project in Coursera's `Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization` but will be implemented using `Tensorflow 2`.  \n",
    "<img src=\"images/hand-gestures.png\">  \n",
    "  \n",
    "Let's start with the modules needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "\n",
    "We load the dataset from the H5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (1080, 64, 64, 3)\n",
      "train_y's shape: (1080, 1)\n",
      "test_x's shape: (120, 64, 64, 3)\n",
      "test_y's shape: (120, 1)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "\n",
    "train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])).T\n",
    "test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0])).T\n",
    "\n",
    "print (\"train_set_x_orig's shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y_orig's shape: \" + str(train_set_y_orig.shape))\n",
    "print (\"test_set_x_orig's shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y_orig's shape: \" + str(test_set_y_orig.shape))\n",
    "\n",
    "# normalize values between 0 to 1\n",
    "train_set_x_orig = train_set_x_orig / 255\n",
    "test_set_x_orig = test_set_x_orig / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training samples, we have 1080 `64 x 64 x 3` RGB images while the test samples have 120 RGB images.  \n",
    "  \n",
    "Here are the images from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(train_set_x_orig)):\n",
    "    plt.imshow(train_set_x_orig[index])\n",
    "    print(\"idx(\" + str(index) +\") y(\"+str(train_set_y_orig.T[0,index])+\") : \" + str(classes[train_set_y_orig.T[0,index]]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(test_set_x_orig)):\n",
    "    plt.imshow(test_set_x_orig[index])\n",
    "    print(\"idx(\" + str(index) +\") y(\"+str(test_set_y_orig.T[0,index])+\") : \" + str(classes[test_set_y_orig.T[0,index]]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Let's try to create a 3-layer neural network model for this problem.  \n",
    "Note that the problem now has `multiple classes for classification` which can be extended from the `binary classification` problem.  \n",
    "  \n",
    "This command is called first to avoid casting of float64 to float32 (Tensorflow warning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "model_dir = 'models/initial_model'  # used for saving and loading a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we did in the cat classification problem in [cAIt-sith](https://github.com/scrappycoc0/cAIth-sith), we will make a stack of layers using Tensorflow.  \n",
    "What differs from [cAIt-sith](https://github.com/scrappycoc0/cAIth-sith) is that, the last node will require `softmax` activation function since we have a multiple classification problem.  \n",
    "  \n",
    "<font color='red'>Note that we did not put the `softmax` activation on purpose as we plan to use the logits output instead.</font>  \n",
    "See the more helpful explanation from [Tensorflow](https://www.tensorflow.org/tutorials/quickstart/beginner) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                307225    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                312       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 78        \n",
      "=================================================================\n",
      "Total params: 307,615\n",
      "Trainable params: 307,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_of_possible_output = 6 # 0 - 5 values using 1-hand gesture\n",
    "\n",
    "# hyperparameters\n",
    "model_struct = [(25, 'relu'), (12, 'relu')]\n",
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.01\n",
    "\n",
    "# create model\n",
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=train_set_x_orig[0].shape),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "\n",
    "# add hidden layers\n",
    "for layer_param in model_struct:\n",
    "    model.add(tf.keras.layers.Dense(layer_param[0], activation=layer_param[1]))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "# final layer for softmax regression\n",
    "model.add(tf.keras.layers.Dense(num_of_possible_output))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset label is represented by a single value between 0 to 5 that represents the hand gestures.  \n",
    "To use Tensorflow, we must do a `one hot encoding` to it.  \n",
    "<img src=\"images/onehot.png\" width=\"500\" height=\"250\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot training shape: (1080, 1, 6)\n",
      "One hot training shape (after reshape): (1080, 6)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding for training labels\n",
    "oh = tf.one_hot(train_set_y_orig, num_of_possible_output) # one hot tensor\n",
    "one_hot_training_labels = oh.numpy()\n",
    "print('One hot training shape: ' + str(one_hot_training_labels.shape))\n",
    "\n",
    "# removes the unnecessary 3rd dimension after tf.one_hot()\n",
    "# turns the (m x 1 x num_of_possible_output) matrix to an (m x num_of_possible_output) vector\n",
    "one_hot_training_labels = one_hot_training_labels.reshape(one_hot_training_labels.shape[0], -1)\n",
    "print('One hot training shape (after reshape): ' + str(one_hot_training_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multiple classification problem, we cannot use the `Binary Cross Entropy` as a loss function.  \n",
    "Instead, we can use [Categorical Cross Entropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy?hl=en) or [Sparse Categorical Cross Entropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy?hl=en).  \n",
    "On the documentation itself, it says that the `Categorical Cross Entropy` expects that the labels are in `one hot encoding`.  \n",
    "Since we already performed the `one hot encoding` in our labels, we might as well use the `Categorical Cross Entropy`.  \n",
    "  \n",
    "Note here that the `tf.nn.softmax()` converts the logits to probabilities in the prediction, so we can:\n",
    "1. Use the probabilities and the loss function where the parameter `from_logits=False`, or\n",
    "2. Use the logits and the loss function where the parameter `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss is 1.897217869758606\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# prediction\n",
    "predictions = model(train_set_x_orig).numpy()\n",
    "\n",
    "print('Initial loss is ' + str(loss_function(one_hot_training_labels, predictions).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the optimizer and metric to have the compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optim_adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compilation\n",
    "model.compile(optimizer=optim_adam, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.8070 - accuracy: 0.1833 0s - loss:\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.7944 - accuracy: 0.1796\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.7781 - accuracy: 0.2083\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.7446 - accuracy: 0.2463 0s - loss: 1.7540 - accura\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.7297 - accuracy: 0.2417\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.7091 - accuracy: 0.2806\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 1.6924 - accuracy: 0.2704\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.6616 - accuracy: 0.3241 0s - loss: 1.6666 - accura\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.6672 - accuracy: 0.3000\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.6453 - accuracy: 0.3343\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.6065 - accuracy: 0.3593\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.6141 - accuracy: 0.3370 0s - loss: 1.6142 - accuracy: 0.33\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.5732 - accuracy: 0.3778\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.5618 - accuracy: 0.3796\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.5393 - accuracy: 0.3991\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.5237 - accuracy: 0.4037\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.5081 - accuracy: 0.3963\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 1.4922 - accuracy: 0.4148\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.4672 - accuracy: 0.4259\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.4452 - accuracy: 0.4417\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.4469 - accuracy: 0.4435\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.4323 - accuracy: 0.4398 0s - loss: 1.4\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.4164 - accuracy: 0.4620 0s - loss:\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.3976 - accuracy: 0.4602\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.3744 - accuracy: 0.4861\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.3608 - accuracy: 0.4917\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.3596 - accuracy: 0.4778\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.3294 - accuracy: 0.5056\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 1.3627 - accuracy: 0.4787\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.3588 - accuracy: 0.4722\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 1.3103 - accuracy: 0.5222\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.3071 - accuracy: 0.5120\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.2949 - accuracy: 0.5231\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 1.2951 - accuracy: 0.5259\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 1.2832 - accuracy: 0.5185\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 1.2602 - accuracy: 0.5556 0s - loss: 1.2295 \n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 1.2601 - accuracy: 0.5537\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 1.2559 - accuracy: 0.5519 0s - loss: 1\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 1.2290 - accuracy: 0.5574\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.2247 - accuracy: 0.5454\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.2227 - accuracy: 0.5620\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.2269 - accuracy: 0.5778\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.2411 - accuracy: 0.5630\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.1904 - accuracy: 0.5843\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.1893 - accuracy: 0.5685\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.2030 - accuracy: 0.5509\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.1897 - accuracy: 0.5611\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.1776 - accuracy: 0.5731\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 1.1764 - accuracy: 0.5843\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.1492 - accuracy: 0.5926\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.1343 - accuracy: 0.5926\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.1433 - accuracy: 0.5843\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.1355 - accuracy: 0.5972\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.1065 - accuracy: 0.6000\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.1506 - accuracy: 0.5972\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.1569 - accuracy: 0.5861\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.1019 - accuracy: 0.6000\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.0996 - accuracy: 0.6139\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.1037 - accuracy: 0.5972\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.1179 - accuracy: 0.5972\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.1091 - accuracy: 0.6176\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.0984 - accuracy: 0.6019\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 1.0876 - accuracy: 0.6074\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.0682 - accuracy: 0.6148\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 1.0812 - accuracy: 0.6139\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 1.0688 - accuracy: 0.6287\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 1.0830 - accuracy: 0.6222\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.0374 - accuracy: 0.6315 0s - loss: 1.0204 \n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 1.0552 - accuracy: 0.6213 0s - loss: 1.0\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.0504 - accuracy: 0.6426\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 1.0314 - accuracy: 0.6398\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0389 - accuracy: 0.6417\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.0438 - accuracy: 0.6324\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.0107 - accuracy: 0.6593\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.0178 - accuracy: 0.6398\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 1.0151 - accuracy: 0.6509\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 1.0129 - accuracy: 0.6426\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 1.0068 - accuracy: 0.6500\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 1.0067 - accuracy: 0.6593\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 37ms/step - loss: 1.0147 - accuracy: 0.6259\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 1.0019 - accuracy: 0.6343\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.9948 - accuracy: 0.6454\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 1.0054 - accuracy: 0.6389\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 2s 47ms/step - loss: 1.0061 - accuracy: 0.6398\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 1.0172 - accuracy: 0.6519\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.9867 - accuracy: 0.6602\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.9701 - accuracy: 0.6685\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.9598 - accuracy: 0.6602 0s - loss: 0.9557 - ac\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.9483 - accuracy: 0.6694\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 1.0045 - accuracy: 0.6435\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.9586 - accuracy: 0.6593\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.9705 - accuracy: 0.6620\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9780 - accuracy: 0.6676\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9605 - accuracy: 0.6630\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9756 - accuracy: 0.6556\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.9540 - accuracy: 0.6593\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.9559 - accuracy: 0.6556\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9496 - accuracy: 0.6639\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9557 - accuracy: 0.6537\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.9280 - accuracy: 0.6824\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.9276 - accuracy: 0.6685\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.9486 - accuracy: 0.6630\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.9030 - accuracy: 0.6954\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.9047 - accuracy: 0.6806\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9174 - accuracy: 0.6833\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9306 - accuracy: 0.6722\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9064 - accuracy: 0.6806\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.9385 - accuracy: 0.6657\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9199 - accuracy: 0.6870\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8990 - accuracy: 0.6870\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9008 - accuracy: 0.6889\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.9047 - accuracy: 0.6907\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8856 - accuracy: 0.6991\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8763 - accuracy: 0.6991\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8877 - accuracy: 0.6926\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8712 - accuracy: 0.6981\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8829 - accuracy: 0.6750\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.8782 - accuracy: 0.7009\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8581 - accuracy: 0.6972\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8540 - accuracy: 0.6991\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8680 - accuracy: 0.7065\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8477 - accuracy: 0.6981\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8472 - accuracy: 0.7083\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8432 - accuracy: 0.7157\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8558 - accuracy: 0.6926\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.8481 - accuracy: 0.7019\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8385 - accuracy: 0.7102\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.8382 - accuracy: 0.7093\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.8601 - accuracy: 0.6991 0s - loss: 0.8563 - accuracy: \n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8331 - accuracy: 0.7111\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8422 - accuracy: 0.7037\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.8280 - accuracy: 0.7296 0s - loss: 0.8\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.8261 - accuracy: 0.7213\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.8109 - accuracy: 0.7287\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.8359 - accuracy: 0.7111\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.8325 - accuracy: 0.7204\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.7975 - accuracy: 0.7278\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8084 - accuracy: 0.7333\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.7977 - accuracy: 0.7315\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.8267 - accuracy: 0.7250\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7995 - accuracy: 0.7370\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.7884 - accuracy: 0.7259\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8268 - accuracy: 0.7056\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.8096 - accuracy: 0.7259\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.7970 - accuracy: 0.7333\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.8041 - accuracy: 0.7213\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7991 - accuracy: 0.7222\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.8308 - accuracy: 0.7102\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.7921 - accuracy: 0.7287\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7648 - accuracy: 0.7454 0s - loss: 0.7865 - accuracy\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7681 - accuracy: 0.7306 0s - loss: 0.7741 - accu\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.7805 - accuracy: 0.7398\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7720 - accuracy: 0.7454 0s - loss: 0\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.7954 - accuracy: 0.7278\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.7782 - accuracy: 0.7333\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.7453 - accuracy: 0.7537\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.7891 - accuracy: 0.7306\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.7464 - accuracy: 0.7528\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 29ms/step - loss: 0.7663 - accuracy: 0.7407\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.7403 - accuracy: 0.7454\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.7811 - accuracy: 0.7324\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.7547 - accuracy: 0.7333\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7533 - accuracy: 0.7343\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.7464 - accuracy: 0.7389 0s - loss: 0.7366 - accuracy: 0.\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7580 - accuracy: 0.7250\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.7560 - accuracy: 0.7296\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7717 - accuracy: 0.7407\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7579 - accuracy: 0.7417\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7564 - accuracy: 0.7444 0s - loss: 0.7299 - ac\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7496 - accuracy: 0.7380\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7191 - accuracy: 0.7574 0s - loss:\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7612 - accuracy: 0.7296\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7314 - accuracy: 0.7565\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7305 - accuracy: 0.7509\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7272 - accuracy: 0.7565\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7277 - accuracy: 0.7565\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7415 - accuracy: 0.7454\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.7456 - accuracy: 0.7500\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7475 - accuracy: 0.7454 0s - loss: 0.7472 - \n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7335 - accuracy: 0.7537\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7161 - accuracy: 0.7565\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7109 - accuracy: 0.7593\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7123 - accuracy: 0.7620\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7260 - accuracy: 0.7454\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.7222 - accuracy: 0.7657\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6762 - accuracy: 0.7778\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7091 - accuracy: 0.7556\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.7280 - accuracy: 0.7556\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.7286 - accuracy: 0.7556\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7097 - accuracy: 0.7565 0s - loss:\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6981 - accuracy: 0.7769\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7108 - accuracy: 0.7574\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.7029 - accuracy: 0.7815\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6997 - accuracy: 0.7630\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6954 - accuracy: 0.7667\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6719 - accuracy: 0.7750\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6966 - accuracy: 0.7630\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6794 - accuracy: 0.7685\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6733 - accuracy: 0.7833\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.6688 - accuracy: 0.7824\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.7017 - accuracy: 0.7528\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.6949 - accuracy: 0.7630\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.6733 - accuracy: 0.7685 0s - loss: 0.6711 - accuracy: 0.77\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6829 - accuracy: 0.7731\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6818 - accuracy: 0.7731\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6627 - accuracy: 0.7917\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6480 - accuracy: 0.7944\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6640 - accuracy: 0.7880\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6530 - accuracy: 0.7778\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6770 - accuracy: 0.7852\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6247 - accuracy: 0.7981\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6637 - accuracy: 0.7778\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6388 - accuracy: 0.7898\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6562 - accuracy: 0.7852\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6423 - accuracy: 0.7917\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6345 - accuracy: 0.7889\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6586 - accuracy: 0.7833\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6509 - accuracy: 0.7880\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6529 - accuracy: 0.7898\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6508 - accuracy: 0.7769\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6238 - accuracy: 0.7954\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6407 - accuracy: 0.8009\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6422 - accuracy: 0.7796\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6285 - accuracy: 0.7917\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6201 - accuracy: 0.8000\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6164 - accuracy: 0.8083\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.6339 - accuracy: 0.7852\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.6224 - accuracy: 0.8019\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6403 - accuracy: 0.7889\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6240 - accuracy: 0.7981\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.79 - 1s 26ms/step - loss: 0.6114 - accuracy: 0.7935\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.6248 - accuracy: 0.8000\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6203 - accuracy: 0.7926\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6032 - accuracy: 0.8074\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.6292 - accuracy: 0.7944\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6516 - accuracy: 0.7750\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6297 - accuracy: 0.7944\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6080 - accuracy: 0.8037\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5942 - accuracy: 0.8157\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.6054 - accuracy: 0.8213\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6198 - accuracy: 0.8009\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.6174 - accuracy: 0.7898\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.6118 - accuracy: 0.8037\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5821 - accuracy: 0.8102\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.6392 - accuracy: 0.7861\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5801 - accuracy: 0.8130\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5822 - accuracy: 0.8148\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5961 - accuracy: 0.8093\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.6213 - accuracy: 0.8000\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.6049 - accuracy: 0.8009\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.6165 - accuracy: 0.8102\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5980 - accuracy: 0.8157\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5848 - accuracy: 0.8056\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.6149 - accuracy: 0.8130\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5623 - accuracy: 0.8250\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5887 - accuracy: 0.8167\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5650 - accuracy: 0.8222\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6121 - accuracy: 0.8028\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5721 - accuracy: 0.8167 0s - loss: 0.5734 - accuracy: 0.\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5766 - accuracy: 0.8093\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5802 - accuracy: 0.8176\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.6043 - accuracy: 0.8157\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5851 - accuracy: 0.8111\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5480 - accuracy: 0.8278\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5517 - accuracy: 0.8324\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5452 - accuracy: 0.8278\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5771 - accuracy: 0.8176 0s - los\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5678 - accuracy: 0.8241 0s - loss: 0.5732 - accuracy: 0.82\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5697 - accuracy: 0.8176\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5578 - accuracy: 0.8324\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5745 - accuracy: 0.8139\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.5603 - accuracy: 0.8139 0s - loss:\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.5393 - accuracy: 0.8296\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5541 - accuracy: 0.8148\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.82 - 1s 29ms/step - loss: 0.5407 - accuracy: 0.8231\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.5409 - accuracy: 0.8213\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5573 - accuracy: 0.8130 0s - loss:\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.5743 - accuracy: 0.8157\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.5496 - accuracy: 0.8231\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5634 - accuracy: 0.8074\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5070 - accuracy: 0.8343\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5655 - accuracy: 0.8343\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5124 - accuracy: 0.8324\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.5303 - accuracy: 0.8343\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.5393 - accuracy: 0.8333\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5357 - accuracy: 0.8435\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5246 - accuracy: 0.8435\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5324 - accuracy: 0.8389\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5543 - accuracy: 0.8269\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5327 - accuracy: 0.8352\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5300 - accuracy: 0.8213\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.84 - 1s 26ms/step - loss: 0.5304 - accuracy: 0.8407\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.5134 - accuracy: 0.8352\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5331 - accuracy: 0.8231\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5335 - accuracy: 0.8306\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5256 - accuracy: 0.8426\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5379 - accuracy: 0.8361\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5007 - accuracy: 0.8454\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5386 - accuracy: 0.8250\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5215 - accuracy: 0.8306 0s - loss: 0.5212 - accuracy: \n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5174 - accuracy: 0.8287\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.5366 - accuracy: 0.8333\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4925 - accuracy: 0.8352\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5493 - accuracy: 0.8222\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.4996 - accuracy: 0.8389\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5379 - accuracy: 0.8324 0s - loss: 0.5353 - accuracy: 0.83\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.5130 - accuracy: 0.8380\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5184 - accuracy: 0.8417\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4998 - accuracy: 0.8528\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.5251 - accuracy: 0.8407\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.5022 - accuracy: 0.8435\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5081 - accuracy: 0.8389\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.5404 - accuracy: 0.8352\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 2s 54ms/step - loss: 0.5132 - accuracy: 0.8361\n",
      "Epoch 315/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4846 - accuracy: 0.8528\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.5044 - accuracy: 0.8565\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4905 - accuracy: 0.8565\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.5039 - accuracy: 0.8537\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4933 - accuracy: 0.8509\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.5012 - accuracy: 0.8500 0s - loss: 0.5159 - ac\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.5027 - accuracy: 0.8519\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4824 - accuracy: 0.8639\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.5045 - accuracy: 0.8444\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4838 - accuracy: 0.8500\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4878 - accuracy: 0.8509\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4992 - accuracy: 0.8389\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4913 - accuracy: 0.8500\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4759 - accuracy: 0.8556\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.4461 - accuracy: 0.8546\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4826 - accuracy: 0.8537\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.4734 - accuracy: 0.8546\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.5082 - accuracy: 0.8435\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4841 - accuracy: 0.8528\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4563 - accuracy: 0.8602\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4838 - accuracy: 0.8509\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.5035 - accuracy: 0.8454\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4751 - accuracy: 0.8611\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4785 - accuracy: 0.8528\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4979 - accuracy: 0.8454\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4624 - accuracy: 0.8565\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4637 - accuracy: 0.8565\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4767 - accuracy: 0.8556\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.5192 - accuracy: 0.8417\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4710 - accuracy: 0.8463 0s - loss: 0.4667 - accuracy: 0.84\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4729 - accuracy: 0.8565\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4463 - accuracy: 0.8620\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4509 - accuracy: 0.8639 0s - loss: 0.4428 - ac\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4954 - accuracy: 0.8657\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.4797 - accuracy: 0.8509\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4948 - accuracy: 0.8528\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 0.4688 - accuracy: 0.8565\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4950 - accuracy: 0.8481 0s - loss: 0.4917 - accuracy: 0.\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4422 - accuracy: 0.8722\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.4685 - accuracy: 0.8500\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4776 - accuracy: 0.8537 0s - loss: 0.4694 - accuracy: 0.\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4533 - accuracy: 0.8620\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4603 - accuracy: 0.8519\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4574 - accuracy: 0.8583\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.4970 - accuracy: 0.8500\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4617 - accuracy: 0.8676\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.4420 - accuracy: 0.8648\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4593 - accuracy: 0.8630\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4132 - accuracy: 0.8796\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.4653 - accuracy: 0.8574\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4426 - accuracy: 0.8741\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.87 - 1s 30ms/step - loss: 0.4407 - accuracy: 0.8704\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.4368 - accuracy: 0.8639\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4309 - accuracy: 0.8750\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4471 - accuracy: 0.8676\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4696 - accuracy: 0.8611\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 2s 48ms/step - loss: 0.4371 - accuracy: 0.8694\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 1s 40ms/step - loss: 0.4602 - accuracy: 0.8556\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 0.4181 - accuracy: 0.8685\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.4184 - accuracy: 0.8778\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.4460 - accuracy: 0.8676\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.4444 - accuracy: 0.8704\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 0.4248 - accuracy: 0.8778 0s - loss: 0.3\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4539 - accuracy: 0.8639\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4283 - accuracy: 0.8639\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4285 - accuracy: 0.8648\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4287 - accuracy: 0.8713\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4339 - accuracy: 0.8657\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.4166 - accuracy: 0.8704\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4442 - accuracy: 0.8648\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4312 - accuracy: 0.8574\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4196 - accuracy: 0.8713\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4401 - accuracy: 0.8676\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.4439 - accuracy: 0.8741\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.4080 - accuracy: 0.8778\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.3825 - accuracy: 0.8833\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4009 - accuracy: 0.8806\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3918 - accuracy: 0.8861\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4322 - accuracy: 0.8741\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4368 - accuracy: 0.8583\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3979 - accuracy: 0.8741\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3950 - accuracy: 0.8843\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.3958 - accuracy: 0.8861\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.3923 - accuracy: 0.8815 0s - loss: 0.3935 - accuracy: \n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4061 - accuracy: 0.8796 0s - loss: 0.3944 - accura\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4175 - accuracy: 0.8741\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4233 - accuracy: 0.8694\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3941 - accuracy: 0.8806\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4321 - accuracy: 0.8731\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4266 - accuracy: 0.8713\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3997 - accuracy: 0.8787\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.4262 - accuracy: 0.8676\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4273 - accuracy: 0.8796\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.3991 - accuracy: 0.8907\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3970 - accuracy: 0.8731\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.3708 - accuracy: 0.8870\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3695 - accuracy: 0.8852\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4017 - accuracy: 0.8778\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3835 - accuracy: 0.8806 0s - loss: 0.3738 - accura\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 0.3792 - accuracy: 0.8944\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3853 - accuracy: 0.8852\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4006 - accuracy: 0.8778 0s - loss: 0.4\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4065 - accuracy: 0.8861 0s - loss: 0\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.4126 - accuracy: 0.8685\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3925 - accuracy: 0.8815\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3856 - accuracy: 0.8870\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.4066 - accuracy: 0.8852\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.3686 - accuracy: 0.8917\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.4040 - accuracy: 0.8750\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3686 - accuracy: 0.8944\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.4023 - accuracy: 0.8852\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.4069 - accuracy: 0.8769\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3863 - accuracy: 0.8824\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3922 - accuracy: 0.8843\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3893 - accuracy: 0.8759\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.3610 - accuracy: 0.8889\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3792 - accuracy: 0.8833\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3919 - accuracy: 0.8861\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.3691 - accuracy: 0.8935\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.4193 - accuracy: 0.8750 0s - loss: 0.4134 - accura\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3935 - accuracy: 0.8796\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3820 - accuracy: 0.8963\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3811 - accuracy: 0.8833\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3912 - accuracy: 0.8843\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3733 - accuracy: 0.8944\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.4078 - accuracy: 0.8787\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3776 - accuracy: 0.8861\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3733 - accuracy: 0.8870\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.4110 - accuracy: 0.8778\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3419 - accuracy: 0.9028\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3436 - accuracy: 0.9083\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3838 - accuracy: 0.8824\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3653 - accuracy: 0.8935\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.4200 - accuracy: 0.8769\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3700 - accuracy: 0.8833\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3618 - accuracy: 0.8917\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.3557 - accuracy: 0.9028\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3999 - accuracy: 0.8741\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3615 - accuracy: 0.8972 0s - loss:\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3876 - accuracy: 0.8741\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3570 - accuracy: 0.8907\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3739 - accuracy: 0.8861\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.3519 - accuracy: 0.8907\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3759 - accuracy: 0.8815\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3554 - accuracy: 0.8972\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.3912 - accuracy: 0.8778\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3285 - accuracy: 0.9009 0s - loss:\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3462 - accuracy: 0.8944\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3560 - accuracy: 0.8963\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3566 - accuracy: 0.9009\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.3823 - accuracy: 0.8806\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3838 - accuracy: 0.8898\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3936 - accuracy: 0.8861\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3962 - accuracy: 0.8917\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3575 - accuracy: 0.8944\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3406 - accuracy: 0.8991\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3435 - accuracy: 0.9000\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3672 - accuracy: 0.8972\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3104 - accuracy: 0.9093\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3472 - accuracy: 0.8972\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3298 - accuracy: 0.9065\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.3443 - accuracy: 0.9009\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3163 - accuracy: 0.9167\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3266 - accuracy: 0.9074\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.3570 - accuracy: 0.8972\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3725 - accuracy: 0.9009\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3511 - accuracy: 0.9028\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3465 - accuracy: 0.9056\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3945 - accuracy: 0.8898\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3146 - accuracy: 0.9120 0s - loss: 0.3\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3171 - accuracy: 0.9000\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3138 - accuracy: 0.9111\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3517 - accuracy: 0.9000\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3811 - accuracy: 0.8833\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.3295 - accuracy: 0.9046\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3394 - accuracy: 0.8972\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3550 - accuracy: 0.8981\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3372 - accuracy: 0.8935\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3323 - accuracy: 0.9046\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3412 - accuracy: 0.9065\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3166 - accuracy: 0.9093\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3433 - accuracy: 0.8944\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3140 - accuracy: 0.9120\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3259 - accuracy: 0.8972\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3170 - accuracy: 0.9056\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3581 - accuracy: 0.8981\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set_x_orig, one_hot_training_labels, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model which can be loaded next time to avoid re-training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/initial_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "The current model we have has a training set accuracy of <b>89.81%</b>.  \n",
    "Before we check the test set accuracy, we convert the test set labels to `one hot encoding` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot test shape: (120, 1, 6)\n",
      "One hot test shape (after reshape): (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding for test labels\n",
    "oh = tf.one_hot(test_set_y_orig, num_of_possible_output) # one hot tensor\n",
    "one_hot_test_labels = oh.numpy()\n",
    "print('One hot test shape: ' + str(one_hot_test_labels.shape))\n",
    "\n",
    "# removes the unnecessary 3rd dimension after tf.one_hot()\n",
    "# turns the (m x 1 x num_of_possible_output) matrix to an (m x num_of_possible_output) vector\n",
    "one_hot_test_labels = one_hot_test_labels.reshape(one_hot_test_labels.shape[0], -1)\n",
    "print('One hot test shape (after reshape): ' + str(one_hot_test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate the model's test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5945025682449341, 0.7666666666666667]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set_x_orig, one_hot_test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This <b>76.67%</b> test set accuracy is a fair performance for such a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error Analysis\n",
    "\n",
    "We can check some of the model's error just in case there are"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
